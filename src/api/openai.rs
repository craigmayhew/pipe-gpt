use atty::Stream; // atty to determine if data is piped in or not
use log::*; // logging
use openai_api_rust::{
    // openai api
    chat::{ChatApi, ChatBody},
    Auth,
    Message,
    OpenAI,
    Role,
};
use regex::Regex;

use crate::config::models::load_config;

pub enum AssistantPurpose {
    CodeReviewer,
    Default,
}

impl ToString for AssistantPurpose {
    fn to_string(&self) -> String {
        match self {
            AssistantPurpose::Default => {
                "You are a helpful assistant.".to_string()
            }
            AssistantPurpose::CodeReviewer => {
                "You are a helpful assistant. How would you improve this code? Include line numbers in your comments so I can tell where you mean. ".to_string()
            }
        }
    }
}

/// Counts the approximate number of tokens in a given text string based on a simple regex pattern.
/// This function estimates the number of tokens using two regex patterns:
/// - `\w+` to match sequences of word characters
/// - `[^\w\s]` to match individual non-word, non-space characters
///
/// # Arguments
///
/// * `text` - A reference to a string slice that holds the text to be tokenized.
///
/// # Returns
///
/// Returns the count of estimated tokens in the input text.
///
/// # Examples
///
/// ```
/// let sample_text = "Hello, world! This is a test to count tokens.";
/// let token_count = count_tokens(sample_text);
/// assert_eq!(token_count, 11);
/// ```
pub fn count_tokens(text: &str) -> usize {
    let re = Regex::new(r"\w+|[^\w\s]").unwrap();
    re.find_iter(text).count()
}

/// # Create Conversation Vector
///
/// Add the prepend string if present. Add piped stream if present.
pub fn create_conversation(
    prepend: &str,
    input: &str,
    purpose: &AssistantPurpose,
) -> Vec<openai_api_rust::Message> {
    let mut conversation_messages = vec![Message {
        role: Role::System,
        content: purpose.to_string(),
    }];
    if !&prepend.is_empty() {
        conversation_messages.push(Message {
            role: Role::User,
            content: prepend.to_string(),
        });
    }
    // if data was piped into this application, add it to the conversation
    // This is useful even if the input is blank, as a form of debug, GPT will likely respond with ~"It looks like you forgot the data"
    if !atty::is(Stream::Stdin) {
        conversation_messages.push(Message {
            role: Role::User,
            content: input.to_string(),
        });
    }

    conversation_messages
}

/// # Send Request To Openai API
///
/// Loads the OPENAI_API_KEY environment variable, connects to OpenAI API, sends chat
pub async fn send_to_gpt4(body: ChatBody) -> Result<String, reqwest::Error> {
    // debug log
    debug!("entered send_to_gpt4()");

    let config = load_config();
    let api_url = config.api_url;

    let api_key = std::env::var("AI_API_KEY")
        .map_err(|_| "Missing AI_API_KEY".to_string())
        .expect("Failed to read auth from environment");

    let auth = Auth::new(&api_key);
    let openai = OpenAI::new(auth, &api_url);
    let chat_completion = openai
        .chat_completion_create(&body)
        .expect("chat completion failed");
    let choice = chat_completion.choices;
    let message = &choice[0]
        .message
        .as_ref()
        .expect("Failed to read message from API");
    // debug log
    debug!("message recieved {:?}", message);

    Ok(message.content.to_string())
}
#[cfg(any(test, doc))]
mod tests {
    use super::*;

    /// Test that piped input is not detected
    #[cfg_attr(not(doc), test)]
    fn test_create_conversation_no_pipe() {
        let p_text = "This is the prepend";

        let prepend = p_text;
        let input = "This is the piped input. It won't be piped as part of the test".to_string();
        let purpose = AssistantPurpose::Default;

        let conversation = create_conversation(prepend, &input, &purpose);
        //TODO: Investigate why this is 3 != 2 in github actions but 2 == 2 when run locally
        //assert_eq!(conversation.len(), 2); // then len is only two instead of three because piping isn't active here
        assert_eq!(conversation[1].content, p_text);
    }

    /// Test an API call using an API key
    #[cfg_attr(not(doc), tokio::test)]
    async fn test_send_to_gpt4() {
        let config = load_config();
        // Note: This test requires a valid API key set in the environment
        let body = ChatBody {
            model: config.model,
            max_tokens: Some(config.max_tokens),
            temperature: Some(config.temperature),
            top_p: Some(0.95),
            n: Some(1),
            stream: Some(false),
            stop: None,
            presence_penalty: None,
            frequency_penalty: None,
            logit_bias: None,
            user: None,
            messages: vec![Message {
                role: Role::User,
                content: "Translate this to English please.".to_string(),
            }],
        };

        let result = send_to_gpt4(body).await;

        assert!(result.is_ok());
    }
}
